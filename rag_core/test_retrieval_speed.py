import time
import re
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

# ğŸ”¹ Load E5 embedding model
print("ğŸ” Loading embedding model (E5)...")
embeddings = HuggingFaceEmbeddings(
    model_name="intfloat/multilingual-e5-base"
)

# ğŸ”¹ Confirm embedding dimension
test_vec = embeddings.embed_query("test")
print("Embedding dimension:", len(test_vec))

# ğŸ”¹ Load FAISS index
print("ğŸ“‚ Loading FAISS index...")
db = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)

print(f"ğŸ“Š Total vectors in index: {db.index.ntotal}")

# ğŸ”¹ Sanskrit query (E5 models prefer 'query:' prefix)
query = "query: à¤®à¥‚à¤°à¥à¤–à¤­à¥ƒà¤¤à¥à¤¯à¤¸à¥à¤¯ à¤•à¤¥à¤¾ à¤•à¤¾"
print(f"\nğŸ§  Running retrieval for query: {query}")

# â± Retrieval timing
start_time = time.time()
docs_and_scores = db.similarity_search_with_score(query, k=2)
end_time = time.time()

print(f"\nâ± Retrieval Time: {end_time - start_time:.4f} seconds")

# ğŸ”¹ Display retrieved chunks (cleaned)
for i, (doc, score) in enumerate(docs_and_scores):
    print(f"\nğŸ“œ Result {i+1}  |  Similarity Score: {score:.4f}")
    
    # Clean extra blank lines for nicer display
    cleaned_text = re.sub(r'\n\s*\n+', '\n\n', doc.page_content).strip()
    
    print(cleaned_text[:600])
